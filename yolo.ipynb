{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: Jupyter cannot be started. Error attempting to locate jupyter: Error: Module 'notebook' not installed.",
     "output_type": "error"
    }
   ],
   "source": [
    "# YOLO model:\n",
    "The YOLO model has been trained using a C implementation called darknet. this example uses a fork from AlexeyAB, that allows training YOLO using darknet. Therefore, the following are the scripts to call to perform the different operations.\n",
    "\n",
    "First, make sure submodules are initiated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git submodule init"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Compile darknet for use on the HPC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./compile_darknet.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "\n",
    "First, from within the scripts/YOLO folder, call fish_label.py\n",
    "This generates the training and validation text files.\n",
    "\n",
    "After having generated the json files from the front-end, call add_from_network.py to include the new images to the training set. The validation set stays the same.\n",
    "\n",
    "To train using the HPC, queue up for use with 2 graphics cards using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bsub < queueYolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./queueYolo"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inference\n",
    "\n",
    "To perform Inference on all the extracted images from all the videos, set the used weight file in queYolo_inference and the list of files to run inference on in the same file and then queue up or run interactively using the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bsub < queueYolo_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./queueYolo_inference"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mAP on set\n",
    "To calculate the mean average precision on the validation set, change the weight filed pointed to in queueYolo_map to point to the desired .weight file and run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bsub < queueYolo_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./queueYolo_map"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate images with bounding boxes from the result file\n",
    "\n",
    "\n",
    "The following takes a json file and reads in all the detections. It then takes the cases where a minimum of one object was detected by one of two networks. It draws a bounding box and saves the image in the folder that the code was run from. The first network is drawn in red while the second network is drawn in blue.\n",
    "\n",
    "To do this, use the inference script to output the two json files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"/work1/s154227/videos/result_first_500.json\") as file:\n",
    "\tdict_first = json.load(file)\n",
    "with open(\"/work1/s154227/videos/result_second_500.json\") as file:\n",
    "\tdict_second = json.load(file)\n",
    "\n",
    "for i in range(500):\n",
    "\tif len(dict_first[i][\"objects\"]) > 0 or len(dict_second[i][\"objects\"]) > 0:\n",
    "\t\tpath = dict_first[i][\"filename\"]\n",
    "\t\tim = Image.open(path)\n",
    "\t\tdraw = ImageDraw.Draw(im)\n",
    "\t\tfor obj in dict_first[i][\"objects\"]:\n",
    "\t\t\tcoor = obj[\"relative_coordinates\"]\n",
    "\t\t\tx0 = 1280 * coor[\"center_x\"] - 1280*(float(coor[\"width\"])/2)\n",
    "\t\t\tx1 = 1280 * coor[\"center_x\"] + 1280*(float(coor[\"width\"])/2)\n",
    "\t\t\ty0 = 720 * coor[\"center_y\"] - 720*float(coor[\"height\"])/2\n",
    "\t\t\ty1 = 720 * coor[\"center_y\"] + 720*float(coor[\"height\"])/2\n",
    "\t\t\tdraw.rectangle((x0,y0,x1,y1), outline = (255,0,0))\n",
    "\t\t\tdraw.text((x0, y1),str(obj[\"confidence\"]), fill = (255,0,0) )\n",
    "\t\tfor obj in dict_second[i][\"objects\"]:\n",
    "\t\t\tcoor = obj[\"relative_coordinates\"]\n",
    "\t\t\tx0 = 1280 * coor[\"center_x\"] - 1280*float(coor[\"width\"])/2\n",
    "\t\t\tx1 = 1280 * coor[\"center_x\"] + 1280*float(coor[\"width\"])/2\n",
    "\t\t\ty0 = 720 * coor[\"center_y\"] - 720*float(coor[\"height\"])/2\n",
    "\t\t\ty1 = 720 * coor[\"center_y\"] + 720*float(coor[\"height\"])/2\n",
    "\t\t\tdraw.rectangle((x0+2,y0+2,x1+2,y1+2), outline = (0,0,255))\n",
    "\t\t\tdraw.text((x0, y1),str(obj[\"confidence\"]), fill = (0,0,255) )\n",
    "\t\tim.save(path.split(\"/\")[-1])"
   ]
  }
 ]
}