{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification model:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader (PATHS SHOULD BE FIXED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "sys.path.append(os.path.join('.', '..')) # Allow us to import shared custom \n",
    "                                         # libraries, like utils.py\n",
    "\n",
    "image_paths = glob.glob('../../../extracted')\n",
    "len(image_paths)\n",
    "\n",
    "fishies = {\"p virens\" : 0, \"g morhua\": 1, \"h lanceolatus\" : 2, \"background\" : 3}\n",
    "\n",
    "class Fishy(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Description of fishy class\n",
    "\n",
    "    Attributes:\n",
    "        train : Percentage of set used for training.\n",
    "        transform : \n",
    "        data_path : Path to images\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train, transform, data_path='extracted', category_path=\"all_fish.txt\"):\n",
    "        \"\"\"\n",
    "        Constructor for Fishy class\n",
    "\n",
    "            Parameters:\n",
    "                train : Percentage of set used for training.\n",
    "                transform : \n",
    "                data_path : Path to images\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        #data_path = os.path.join(data_path, 'train' if train else 'test')\n",
    "        fp = open(category_path, 'r')\n",
    "        #i.split(\";\")[1][1:-1]\n",
    "\n",
    "        #self.fish_dict =  {i.split(\";\")[0] : fishies[i.split(\";\")[1][1:-1]] for i in fp}\n",
    "        self.fish_dict = {}\n",
    "        count_categories = 0\n",
    "        for i in fp:\n",
    "            if self.fish_dict.get(fishies[i.split(\";\")[1][1:-1]]):\n",
    "                self.fish_dict[fishies[i.split(\";\")[1][1:-1]]].append(i.split(\";\")[0])\n",
    "            else:\n",
    "                self.fish_dict[fishies[i.split(\";\")[1][1:-1]]] = [i.split(\";\")[0]]\n",
    "                count_categories+=1\n",
    "        \n",
    "        self.mostPicturesSameCat = max([len(v) for k,v in self.fish_dict.items()])\n",
    "        self.lengthOfArray = self.mostPicturesSameCat * count_categories\n",
    "        #self.name_to_label = [i.split(\";\")[1][1:-1] for i in fp]\n",
    "        self.image_paths = glob.glob(data_path + '/*.jpg')\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of samples\n",
    "        Returns :\n",
    "            int : The total number of images\n",
    "        \"\"\"\n",
    "        return self.lengthOfArray\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Generates one sample of data\n",
    "\n",
    "        Parameters:\n",
    "            idx (int): Index for image\n",
    "\n",
    "        Returns :\n",
    "            Image : Transformed image.\n",
    "        \"\"\"\n",
    "\n",
    "        category = idx//self.mostPicturesSameCat\n",
    "\n",
    "        pictures = self.fish_dict[category]\n",
    "        idLookup = idx - self.mostPicturesSameCat * category\n",
    "        picture = pictures[idLookup % len(pictures)]\n",
    "\n",
    "        image_path = \"extracted/\" + picture + \".jpg\" #self.image_paths[idx] \n",
    "        \n",
    "        #lookup = image_path.split(\"/\")[-1].split(\".\")[0]\n",
    "        \n",
    "        image = Image.open(image_path)\n",
    "        #y = self.name_to_label[idx]\n",
    "        #y = self.fish_dict[lookup]\n",
    "        X = self.transform(image)\n",
    "        return X,category\n",
    "\n",
    "def createDataLoaders(batch_size, size,rotation = 45, train_distribution = 0.8):\n",
    "    #For testing\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.Resize((size,size)),\n",
    "        transforms.RandomRotation(rotation),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                            (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "    full_dataset = Fishy(train=True, transform=transform)\n",
    "    train_size = int(train_distribution * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    trainset, testset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "    #trainset = Fishy(train=True, transform=transform)\n",
    "    #testset = Fishy(train=False, transform=transform)\n",
    "    train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=6)\n",
    "\n",
    "    return train_loader, test_loader, trainset, testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network declaration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "'''\n",
    "height, width = 512, 512\n",
    "num_classes   = 4\n",
    "\n",
    "channels        = 3        \n",
    "kernel_size     = 3\n",
    "conv_stride     = 1\n",
    "conv_pad        = 1\n",
    "conv_drop_rate  = 0.4\n",
    "'''\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, channels, kernel_size,conv_stride, conv_pad, conv_drop_rate, num_classes, image_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = channels, #3 channels\n",
    "                out_channels = 16, \n",
    "                kernel_size = kernel_size, \n",
    "                stride = conv_stride, \n",
    "                padding = conv_pad),\n",
    "\n",
    "            nn.BatchNorm2d(num_features = 16),\n",
    "\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Dropout2d(p=conv_drop_rate),\n",
    "\n",
    "            nn.Conv2d(in_channels = 16, \n",
    "                out_channels = 32, \n",
    "                kernel_size = kernel_size, \n",
    "                stride = conv_stride, \n",
    "                padding = conv_pad),\n",
    "\n",
    "            nn.BatchNorm2d(num_features = 32),\n",
    "\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Dropout2d(p=conv_drop_rate),\n",
    "\n",
    "            nn.Conv2d(in_channels = 32, \n",
    "                out_channels = 64, \n",
    "                kernel_size = kernel_size, \n",
    "                stride = conv_stride, \n",
    "                padding = conv_pad)\n",
    "\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features = 64 * (image_size//2) * (image_size//2), out_features = 256, bias = True),\n",
    "            \n",
    "            #nn.BatchNorm1d(256),\n",
    "            \n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(in_features = 256, out_features = num_classes, bias = False),\n",
    "\n",
    "            nn.Softmax(dim = 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_img = self.conv(x)\n",
    "        x_img = x_img.view(x_img.shape[0],-1)\n",
    "        \n",
    "        out = self.fc(x_img)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluating network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(\"Using device: \" + device)\n",
    "\n",
    "height, width = 512, 512\n",
    "num_classes   = 4\n",
    "\n",
    "channels        = 3        \n",
    "kernel_size     = 3\n",
    "conv_stride     = 1\n",
    "conv_pad        = 1\n",
    "conv_drop_rate  = 0.4\n",
    "image_size      = 64\n",
    "\n",
    "# Writer will output to ./runs/ directory by default\n",
    "writer = SummaryWriter()\n",
    "\n",
    "network = Net(channels, kernel_size,conv_stride, conv_pad, conv_drop_rate, num_classes, image_size)\n",
    "print(network)\n",
    "network.to(device)\n",
    "LEARNING_RATE = 0.00001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# weight_decay is equal to L2 regularization\n",
    "optimizer = optim.Adam(network.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "#training loop:\n",
    "\n",
    "num_epoch = 50\n",
    "batch_size = 64\n",
    "\n",
    "trainingloader, testloader, trainset, testset = createDataLoaders(batch_size, image_size)\n",
    "train_acc_all = []\n",
    "test_acc_all = []\n",
    "try:\n",
    "    for epoch in tqdm(range(num_epoch)):\n",
    "        running_loss = 0.0\n",
    "        train_correct = 0\n",
    "        for i, data in enumerate(trainingloader, 0):\n",
    "\n",
    "            inputs, labels = data\n",
    "            inputs, labels = Variable(inputs).to(device), Variable(labels).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            optimizer\n",
    "\n",
    "            outputs = network(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss\n",
    "\n",
    "            predicted = outputs.argmax(1)\n",
    "            train_correct += (labels==predicted).sum().cpu().item()\n",
    "            \n",
    "            if i % 10 == 1:\n",
    "                print(\"[%d, %5d] loss: %.3f\" % \n",
    "                    (epoch + 1, i + 1, running_loss/1000))\n",
    "                running_loss = 0.0\n",
    "        \n",
    "        network.eval()\n",
    "        test_correct = 0.0\n",
    "        for data, target in testloader:\n",
    "            data = data.to(device)\n",
    "            with torch.no_grad():\n",
    "                output = network(data)\n",
    "            predicted = output.argmax(1).cpu()\n",
    "            test_correct += (target==predicted).sum().item()\n",
    "\n",
    "        train_acc = train_correct/len(trainset)\n",
    "        test_acc = test_correct/len(testset)\n",
    "        train_acc_all.append(train_acc)\n",
    "        test_acc_all.append(test_acc)\n",
    "        #writer.add_scalar('Loss/train', train_acc, epoch)\n",
    "        #writer.add_scalar('Loss/test', np.random.random(), epoch)\n",
    "        writer.add_scalar('Accuracy/train', train_correct*100//len(trainset), epoch + 1)\n",
    "        writer.add_scalar('Accuracy/test', test_correct*100//len(testset), epoch + 1)\n",
    "        if epoch % 3 == 0:\n",
    "            writer.flush()\n",
    "        print(\"Accuracy train: {train:.1f}%\\t test: {test:.1f}%\".format(test=100*test_acc, train=100*train_acc))\n",
    "except(KeyboardInterrupt):\n",
    "    print(\"Model saved\")\n",
    "    torch.save(network, \"model.pt\")\n",
    "    writer.close()\n",
    "    \n",
    "print(\"training over\")\n",
    "\n",
    "#torch.save(network, \"model.pt\")\n",
    "\n",
    "print(\"Saved model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
